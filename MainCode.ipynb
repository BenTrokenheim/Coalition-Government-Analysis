{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7163351,"sourceType":"datasetVersion","datasetId":4137757},{"sourceId":7164038,"sourceType":"datasetVersion","datasetId":4138224},{"sourceId":7177661,"sourceType":"datasetVersion","datasetId":4148129},{"sourceId":7178193,"sourceType":"datasetVersion","datasetId":4148516},{"sourceId":7887307,"sourceType":"datasetVersion","datasetId":4630274}],"dockerImageVersionId":30615,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Import all necessary packages from sklearn & python libraries\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nimport sklearn.model_selection as skm\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import (accuracy_score ,log_loss)\nfrom sklearn.metrics import r2_score\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\n\nfrom sklearn import tree\nfrom sklearn.tree import (DecisionTreeClassifier as DTC ,DecisionTreeRegressor as DTR ,plot_tree ,export_text)\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.tree import export_text\nfrom sklearn.tree import export_graphviz\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\n\nimport matplotlib.pyplot as plt\n\nimport graphviz\nfrom graphviz import Source\n\nimport seaborn as sns\n\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.pipeline import make_pipeline\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:36:59.273745Z","iopub.execute_input":"2024-03-19T15:36:59.274409Z","iopub.status.idle":"2024-03-19T15:36:59.284789Z","shell.execute_reply.started":"2024-03-19T15:36:59.274366Z","shell.execute_reply":"2024-03-19T15:36:59.283806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import the data\ndf1= pd.read_csv('../input/cabinetproportionsdata/CabinetProportionsData.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:36:59.286093Z","iopub.execute_input":"2024-03-19T15:36:59.287002Z","iopub.status.idle":"2024-03-19T15:36:59.311994Z","shell.execute_reply.started":"2024-03-19T15:36:59.286963Z","shell.execute_reply":"2024-03-19T15:36:59.311191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualize Data**","metadata":{}},{"cell_type":"code","source":"#Histogram of DV\nplt.hist(df1['cabinet_proportion'], bins =10)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:36:59.315031Z","iopub.execute_input":"2024-03-19T15:36:59.316053Z","iopub.status.idle":"2024-03-19T15:36:59.524472Z","shell.execute_reply.started":"2024-03-19T15:36:59.316017Z","shell.execute_reply":"2024-03-19T15:36:59.523259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Zero-inflatd y. Plot y with the non-zero values\nnon_zero_values = df1['cabinet_proportion'][df1['cabinet_proportion'] != 0]\nplt.hist(non_zero_values, bins=10)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:36:59.525799Z","iopub.execute_input":"2024-03-19T15:36:59.526148Z","iopub.status.idle":"2024-03-19T15:36:59.709785Z","shell.execute_reply.started":"2024-03-19T15:36:59.526118Z","shell.execute_reply":"2024-03-19T15:36:59.708705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Histograms of all the variables to see if anything is weird\n\nfor column in df1.columns:\n    # Check if the column contains numerical data\n    if pd.api.types.is_numeric_dtype(df1[column]):\n        # Create a histogram for numerical columns\n        plt.hist(df1[column], bins=10)\n        \n        # Set plot title and labels\n        plt.title(f'Histogram of {column}')\n        plt.xlabel(column)\n        plt.ylabel('Frequency')\n        \n        # Show the plot\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:36:59.711687Z","iopub.execute_input":"2024-03-19T15:36:59.712216Z","iopub.status.idle":"2024-03-19T15:37:13.971684Z","shell.execute_reply.started":"2024-03-19T15:36:59.712183Z","shell.execute_reply":"2024-03-19T15:37:13.970534Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scatterplots of all the variables\n\ndv_column = 'cabinet_proportion'\n\nfor column in df1.columns:\n    # Check if the column contains numerical data and is not the DV column\n    if pd.api.types.is_numeric_dtype(df1[column]) and column != dv_column:\n        # Create a scatter plot\n        plt.scatter(df1[column], df1[dv_column])\n        \n        # Set plot title and labels\n        plt.title(f'Scatter Plot of {column} vs {dv_column}')\n        plt.xlabel(column)\n        plt.ylabel(dv_column)\n        \n        # Show the plot\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:13.975802Z","iopub.execute_input":"2024-03-19T15:37:13.976732Z","iopub.status.idle":"2024-03-19T15:37:27.247082Z","shell.execute_reply.started":"2024-03-19T15:37:13.976691Z","shell.execute_reply":"2024-03-19T15:37:27.246206Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#See columns with missingness\n\ndef count_missing_values(dataframe):\n    # Check for missing values in each column\n    missing_values = dataframe.isnull().sum()\n\n    # Create a new DataFrame to store the results\n    missingness_df1 = pd.DataFrame({\n        'Column': missing_values.index,\n        'Missing Rows': missing_values.values\n    })\n\n    return missingness_df1\n\npd.set_option('display.max_rows', None)\n\n#Print dataframe\nresult = count_missing_values(df1)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:27.248407Z","iopub.execute_input":"2024-03-19T15:37:27.249264Z","iopub.status.idle":"2024-03-19T15:37:27.259958Z","shell.execute_reply.started":"2024-03-19T15:37:27.249232Z","shell.execute_reply":"2024-03-19T15:37:27.258955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Heat map of all the numerical columns\n\n# Select only the numerical columns\nnumerical_columns = df1.select_dtypes(include='number')\n\n# Create a heatmap\nplt.figure(figsize=(25, 25))\nsns.heatmap(numerical_columns.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n\n# Set plot title\nplt.title('Correlation Heatmap of Numerical Variables')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:27.261358Z","iopub.execute_input":"2024-03-19T15:37:27.262225Z","iopub.status.idle":"2024-03-19T15:37:34.415614Z","shell.execute_reply.started":"2024-03-19T15:37:27.262193Z","shell.execute_reply":"2024-03-19T15:37:34.414524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\n\n#Summarize the data\ndf1.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:34.419109Z","iopub.execute_input":"2024-03-19T15:37:34.419467Z","iopub.status.idle":"2024-03-19T15:37:34.600862Z","shell.execute_reply.started":"2024-03-19T15:37:34.419418Z","shell.execute_reply":"2024-03-19T15:37:34.599800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import imputed data. Imputed here just means that I filled in the missing coalition values with 0\n#df1 = pd.read_csv('../input/imputeddata/ImputedDataFinal.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:34.602176Z","iopub.execute_input":"2024-03-19T15:37:34.602526Z","iopub.status.idle":"2024-03-19T15:37:34.606799Z","shell.execute_reply.started":"2024-03-19T15:37:34.602497Z","shell.execute_reply":"2024-03-19T15:37:34.605800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Delete row with -9999 outlier\ndf1 = df1[df1['caretaker'] != -9999]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:34.608038Z","iopub.execute_input":"2024-03-19T15:37:34.608341Z","iopub.status.idle":"2024-03-19T15:37:34.620193Z","shell.execute_reply.started":"2024-03-19T15:37:34.608314Z","shell.execute_reply":"2024-03-19T15:37:34.619323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Describe again\ndf1.describe()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:34.621687Z","iopub.execute_input":"2024-03-19T15:37:34.621990Z","iopub.status.idle":"2024-03-19T15:37:34.781188Z","shell.execute_reply.started":"2024-03-19T15:37:34.621962Z","shell.execute_reply":"2024-03-19T15:37:34.780008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Find mean and standard deviation of these columns before deleting the rows\nmean_cabinet_proportion = df1['cabinet_proportion'].mean()\nstd_cabinet_proportion = df1['cabinet_proportion'].std()\nmean_left_rightx = df1['left_rightx'].mean()\nmean_left_righty = df1['left_righty'].mean()\nstd_left_rightx = df1['left_rightx'].std()\nstd_left_righty = df1['left_righty'].std()\n\n\n# Print the mean and standard deviation\nprint(f\"Mean of 'cabinet_proportion' column: {mean_cabinet_proportion}\")\nprint(f\"Standard Deviation of 'cabinet_proportion' column: {std_cabinet_proportion}\")\nprint(f\"Mean of 'left_rightx' column: {mean_left_rightx}\")\nprint(f\"Standard Deviation of 'mean_left_rightx' column: {std_left_rightx}\")\nprint(f\"Mean of 'mean_left_righty' column: {mean_left_righty}\")\nprint(f\"Standard Deviation of 'mean_left_righty' column: {std_left_righty}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:34.782946Z","iopub.execute_input":"2024-03-19T15:37:34.783283Z","iopub.status.idle":"2024-03-19T15:37:34.793627Z","shell.execute_reply.started":"2024-03-19T15:37:34.783252Z","shell.execute_reply":"2024-03-19T15:37:34.792519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print out distribution of countries before deleting missingness\ncountry_counts = df1['country'].value_counts()\n\n# Display the count of each country\nprint(\"Count of each country:\")\nprint(country_counts)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:34.795110Z","iopub.execute_input":"2024-03-19T15:37:34.795554Z","iopub.status.idle":"2024-03-19T15:37:34.808123Z","shell.execute_reply.started":"2024-03-19T15:37:34.795521Z","shell.execute_reply":"2024-03-19T15:37:34.806759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#See what country distribution is using pie chart\n\ncountry_counts = df['country'].value_counts()\n\n# Plot a pie chart\nplt.figure(figsize=(8, 8))\nplt.pie(country_counts, labels=country_counts.index, autopct='%1.1f%%', startangle=90)\n\n# Set plot title\nplt.title('Distribution of Countries')\n\n# Display the pie chart\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:34.809527Z","iopub.execute_input":"2024-03-19T15:37:34.809949Z","iopub.status.idle":"2024-03-19T15:37:35.072596Z","shell.execute_reply.started":"2024-03-19T15:37:34.809904Z","shell.execute_reply":"2024-03-19T15:37:35.071454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop missingness in the left_right columns\ndf1 = df1.dropna(subset=['left_rightx', 'left_righty'])","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:35.074169Z","iopub.execute_input":"2024-03-19T15:37:35.075397Z","iopub.status.idle":"2024-03-19T15:37:35.084416Z","shell.execute_reply.started":"2024-03-19T15:37:35.075344Z","shell.execute_reply":"2024-03-19T15:37:35.083123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculate new mean and standard deviation after deleting missingness\nmean_cabinet_proportion2 = df1['cabinet_proportion'].mean()\nstd_cabinet_proportion2 = df1['cabinet_proportion'].std()\nmean_left_rightx2 = df1['left_rightx'].mean()\nmean_left_righty2 = df1['left_righty'].mean()\nstd_left_rightx2 = df1['left_rightx'].std()\nstd_left_righty2 = df1['left_righty'].std()\n\n# Print the mean and standard deviation\nprint(f\"Mean of 'cabinet_proportion' column: {mean_cabinet_proportion2}\")\nprint(f\"Standard Deviation of 'cabinet_proportion' column: {std_cabinet_proportion2}\")\nprint(f\"Mean of 'left_rightx' column: {mean_left_rightx2}\")\nprint(f\"Standard Deviation of 'mean_left_rightx' column: {std_left_rightx2}\")\nprint(f\"Mean of 'mean_left_righty' column: {mean_left_righty2}\")\nprint(f\"Standard Deviation of 'mean_left_righty' column: {std_left_righty2}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:35.086094Z","iopub.execute_input":"2024-03-19T15:37:35.086516Z","iopub.status.idle":"2024-03-19T15:37:35.096090Z","shell.execute_reply.started":"2024-03-19T15:37:35.086482Z","shell.execute_reply":"2024-03-19T15:37:35.095016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print out new country distribution\ncountry_counts = df1['country'].value_counts()\n\n# Display the count of each country\nprint(\"Count of each country:\")\nprint(country_counts)\n\n#See what country distribution is using pie chart\n\ncountry_counts1 = df1['country'].value_counts()\n\n# Plot a pie chart\nplt.figure(figsize=(8, 8))\nplt.pie(country_counts1, labels=country_counts1.index, autopct='%1.1f%%', startangle=90)\n\n# Set plot title\nplt.title('Distribution of Countries')\n\n# Display the pie chart\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:35.097394Z","iopub.execute_input":"2024-03-19T15:37:35.098243Z","iopub.status.idle":"2024-03-19T15:37:35.325947Z","shell.execute_reply.started":"2024-03-19T15:37:35.098212Z","shell.execute_reply":"2024-03-19T15:37:35.324725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Standardize the numerical columns\n\ncolumns_to_standardize = ['seats', 'miw_new', 'banzhaf', 'shapley', 'splus', 'left_rightx', 'left_righty', 'total_cabinet_size',\n                         'party_count', 'cab_count', 'seats_share', 'enpp', 'seats_total', 'miw_proportion', 'seats_proportion',\n                         'W', 'coalition_total']\n# Initialize StandardScaler\nscaler = StandardScaler()\n\n# Standardize the selected columns and replace the original values\ndf1[columns_to_standardize] = scaler.fit_transform(df1[columns_to_standardize])\n\n# Display the DataFrame with standardized columns\nprint(df1)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:35.327509Z","iopub.execute_input":"2024-03-19T15:37:35.328433Z","iopub.status.idle":"2024-03-19T15:37:35.500318Z","shell.execute_reply.started":"2024-03-19T15:37:35.328388Z","shell.execute_reply":"2024-03-19T15:37:35.499233Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create separate dataframes for IVs and DV\n\nX = df1.drop('cabinet_proportion', axis=1)  # Dataframe of IVs\ny = df1['cabinet_proportion']  #Dataframe of DV","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:35.501552Z","iopub.execute_input":"2024-03-19T15:37:35.501934Z","iopub.status.idle":"2024-03-19T15:37:35.509431Z","shell.execute_reply.started":"2024-03-19T15:37:35.501905Z","shell.execute_reply":"2024-03-19T15:37:35.508205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dropped variables\n\n#Dropped duplicate columns\nX = X.drop('base', axis=1)\nX = X.drop('country', axis=1)\nX = X.drop('country_id', axis=1)\nX = X.drop('party_name', axis=1)\n\n#Dropped any variable related to cabinet distriubtion (data leakage)\n\nX = X.drop('cabinet_seats', axis=1)\nX = X.drop('total_cabinet_size', axis=1)\nX = X.drop('cabinet_party', axis=1)\nX = X.drop('cab_count', axis=1)\nX = X.drop('largest_cab', axis=1)\n\n#Dropped other descriptive variables that aren't related to DV\n\nX = X.drop('party', axis=1)\nX = X.drop('cabinet_name', axis=1)\nX = X.drop('party_name_english', axis=1)\nX = X.drop('election_date', axis=1)\nX = X.drop('start_date', axis=1)\nX = X.drop('election_id', axis=1)\nX = X.drop('party_id', axis=1)\nX = X.drop('cabinet_id', axis=1)\n\n#Dropped variables that weren't specific to a single party\nX = X.drop('coalition_total', axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:35.510774Z","iopub.execute_input":"2024-03-19T15:37:35.511071Z","iopub.status.idle":"2024-03-19T15:37:35.544398Z","shell.execute_reply.started":"2024-03-19T15:37:35.511046Z","shell.execute_reply":"2024-03-19T15:37:35.543420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Run VIF to see if any multicollinearity stands out\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n\nnumerical_columns = X.select_dtypes(include='number')\n\n# Calculate VIF for each column\nvif_data = pd.DataFrame()\nvif_data[\"Variable\"] = numerical_columns.columns\nvif_data[\"VIF\"] = [VIF(numerical_columns.values, i) for i in range(numerical_columns.shape[1])]\n\n# Display the VIF for each numerical column\nprint(vif_data)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:35.545909Z","iopub.execute_input":"2024-03-19T15:37:35.546220Z","iopub.status.idle":"2024-03-19T15:37:35.770065Z","shell.execute_reply.started":"2024-03-19T15:37:35.546193Z","shell.execute_reply":"2024-03-19T15:37:35.768984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PCA for pivotality variables\ncolumns = ['miw_new', 'banzhaf', 'shapley', 'splus', 'miw_proportion']\n\n# Extract the selected columns\nX_pca = X[columns]\n\n# Perform PCA\nn_components = 5\npca = PCA(n_components=n_components)\nX_pca_result = pca.fit_transform(X_pca)\n\n# Create a DataFrame with the PCA results\npca_columns = [f'PC{i+1}' for i in range(n_components)]\ndf_pca = pd.DataFrame(data=X_pca_result, columns=pca_columns)\n\n# Print the explained variance ratio\nexplained_variance_ratio = pca.explained_variance_ratio_\nprint('Explained Variance Ratio:', explained_variance_ratio)\n\nloadings = pca.components_.T * np.sqrt(pca.explained_variance_)\ndf_loadings = pd.DataFrame(data=loadings, columns=pca_columns, index=columns)\nprint('Loadings:')\nprint(df_loadings)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:35.772095Z","iopub.execute_input":"2024-03-19T15:37:35.772933Z","iopub.status.idle":"2024-03-19T15:37:35.802281Z","shell.execute_reply.started":"2024-03-19T15:37:35.772887Z","shell.execute_reply":"2024-03-19T15:37:35.800973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PCA for seat variables\ncolumns2 = ['seats', 'seats_share', 'seats_total', 'seats_proportion']\n\n# Extract the selected columns\nX_pca2 = X[columns2]\n\n# Perform PCA\nn_components = 4\npca2 = PCA(n_components=n_components)\nX_pca_result2 = pca2.fit_transform(X_pca2)\n\n# Create a DataFrame with the PCA results\npca_columns2 = [f'PC{i+1}' for i in range(n_components)]\ndf_pca2 = pd.DataFrame(data=X_pca_result2, columns=pca_columns2)\n\n# Print the explained variance ratio\nexplained_variance_ratio2 = pca2.explained_variance_ratio_\nprint('Explained Variance Ratio:', explained_variance_ratio2)\n\nloadings2 = pca2.components_.T * np.sqrt(pca2.explained_variance_)\ndf_loadings2 = pd.DataFrame(data=loadings2, columns=pca_columns2, index=columns2)\nprint('Loadings:')\nprint(df_loadings2)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:35.808655Z","iopub.execute_input":"2024-03-19T15:37:35.812076Z","iopub.status.idle":"2024-03-19T15:37:35.838618Z","shell.execute_reply.started":"2024-03-19T15:37:35.812023Z","shell.execute_reply":"2024-03-19T15:37:35.837370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PCA for left_right variables\ncolumns3 = ['left_rightx', 'left_righty']\n\n# Extract the selected columns\nX_pca3 = X[columns3]\n\n# Perform PCA\nn_components = 2\npca3 = PCA(n_components=n_components)\nX_pca_result3 = pca3.fit_transform(X_pca3)\n\n# Create a DataFrame with the PCA results\npca_columns3 = [f'PC{i+1}' for i in range(n_components)]\ndf_pca3 = pd.DataFrame(data=X_pca_result3, columns=pca_columns3)\n\n# Print the explained variance ratio\nexplained_variance_ratio3 = pca3.explained_variance_ratio_\nprint('Explained Variance Ratio:', explained_variance_ratio3)\n\nloadings3 = pca3.components_.T * np.sqrt(pca3.explained_variance_)\ndf_loadings3 = pd.DataFrame(data=loadings3, columns=pca_columns3, index=columns3)\nprint('Loadings:')\nprint(df_loadings3)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:35.845116Z","iopub.execute_input":"2024-03-19T15:37:35.848798Z","iopub.status.idle":"2024-03-19T15:37:35.873212Z","shell.execute_reply.started":"2024-03-19T15:37:35.848744Z","shell.execute_reply":"2024-03-19T15:37:35.872076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create latent pivoltality variable for the IVs that were very well explained in dimension 1, no PCA necessary for more dimensions\n\npivotality_vars = ['banzhaf', 'shapley', 'splus', 'miw_proportion']\n\n# Perform PCA for the specified columns\npivotality = PCA(n_components=1)\nlatent_pivotality = pivotality.fit_transform(X[pivotality_vars])\n\n# Create a new column for the latent_pivotality variable\nX['latent_pivotality'] = latent_pivotality[:, 0]\n\n# Print the explained variance ratio for the chosen columns\nexplained_variance_ratio = pca.explained_variance_ratio_\nprint(f\"Explained Variance Ratio for latent_pivotality: {explained_variance_ratio[0]}\")\n\n# Print the DataFrame with the new latent_pivotality variable\nprint(\"DataFrame with latent_pivotality Variable:\")\nprint(X[['banzhaf', 'shapley', 'splus', 'miw_proportion', 'latent_pivotality']])","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:35.880123Z","iopub.execute_input":"2024-03-19T15:37:35.881819Z","iopub.status.idle":"2024-03-19T15:37:35.918491Z","shell.execute_reply.started":"2024-03-19T15:37:35.881774Z","shell.execute_reply":"2024-03-19T15:37:35.917353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create latent seats variable for the IVs that were very well explained in dimension 1\n\nseats_vars = ['seats', 'seats_share', 'seats_proportion']\n\n# Perform PCA for the specified columns\nseats = PCA(n_components=1)\nlatent_seats = seats.fit_transform(X[seats_vars])\n\n# Create a new column for the latent_seats variable\nX['latent_seats'] = latent_seats[:, 0]\n\n# Print the explained variance ratio for the chosen columns\nexplained_variance_ratio2 = pca2.explained_variance_ratio_\nprint(f\"Explained Variance Ratio for latent_seats: {explained_variance_ratio2[0]}\")\n\n# Print the DataFrame with the new latent_seats variable\nprint(\"DataFrame with latent_seats Variable:\")\nprint(X[['seats', 'seats_share', 'seats_proportion', 'latent_seats']])\nprint(X[['latent_seats']])","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:35.926481Z","iopub.execute_input":"2024-03-19T15:37:35.927151Z","iopub.status.idle":"2024-03-19T15:37:35.965590Z","shell.execute_reply.started":"2024-03-19T15:37:35.927108Z","shell.execute_reply":"2024-03-19T15:37:35.964519Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create latent ideology variable for the IVs that were very well explained in dimension 1\n\nideology_vars = ['left_rightx', 'left_righty']\n\n# Perform PCA for the specified columns\nideology = PCA(n_components=1)\nlatent_ideology = ideology.fit_transform(X[ideology_vars])\n\n# Create a new column for the latent_ideology variable\nX['latent_ideology'] = latent_ideology[:, 0]\n\n# Print the explained variance ratio for the chosen columns\nexplained_variance_ratio3 = pca3.explained_variance_ratio_\nprint(f\"Explained Variance Ratio for latent_seats: {explained_variance_ratio3[0]}\")\n\n# Print the DataFrame with the new latent_ideology variable\nprint(\"DataFrame with latent_ideology Variable:\")\nprint(X[['left_rightx', 'left_righty','latent_ideology']])\nprint(X[['latent_ideology']])","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:35.967509Z","iopub.execute_input":"2024-03-19T15:37:35.967926Z","iopub.status.idle":"2024-03-19T15:37:36.006105Z","shell.execute_reply.started":"2024-03-19T15:37:35.967887Z","shell.execute_reply":"2024-03-19T15:37:36.005000Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scatter plot of latent ideology vs DV\nplt.scatter(X['latent_ideology'], y)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:36.007682Z","iopub.execute_input":"2024-03-19T15:37:36.008111Z","iopub.status.idle":"2024-03-19T15:37:36.260848Z","shell.execute_reply.started":"2024-03-19T15:37:36.008082Z","shell.execute_reply":"2024-03-19T15:37:36.259728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop these variables from X so we don't count them twice\n\nX = X.drop('seats', axis=1)\nX = X.drop('seats_share', axis=1)\nX = X.drop('seats_proportion', axis=1)\nX = X.drop('banzhaf', axis=1)\nX = X.drop('shapley', axis=1)\nX = X.drop('splus', axis=1)\nX = X.drop('miw_proportion', axis=1)\nX = X.drop('left_rightx', axis=1)\nX = X.drop('left_righty', axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:36.262188Z","iopub.execute_input":"2024-03-19T15:37:36.262603Z","iopub.status.idle":"2024-03-19T15:37:36.279634Z","shell.execute_reply.started":"2024-03-19T15:37:36.262575Z","shell.execute_reply":"2024-03-19T15:37:36.278581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.columns","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:36.280916Z","iopub.execute_input":"2024-03-19T15:37:36.281231Z","iopub.status.idle":"2024-03-19T15:37:36.288224Z","shell.execute_reply.started":"2024-03-19T15:37:36.281203Z","shell.execute_reply":"2024-03-19T15:37:36.286937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform a train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=50)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:36.289641Z","iopub.execute_input":"2024-03-19T15:37:36.290086Z","iopub.status.idle":"2024-03-19T15:37:36.301602Z","shell.execute_reply.started":"2024-03-19T15:37:36.290050Z","shell.execute_reply":"2024-03-19T15:37:36.300514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Decision Tree**","metadata":{}},{"cell_type":"code","source":"#Unpruned decision tree\n\n#Throw everything at it see what we get\nregressor = DecisionTreeRegressor(max_depth=5)\n\n# Fit the model on the training data\nregressor.fit(X_train, y_train)\n\n# Make predictions on the training set\ny_train_pred = regressor.predict(X_train)\n\n# Calculate MSE and R-squared for training data\nmse_train = mean_squared_error(y_train, y_train_pred)\nr2_train = r2_score(y_train, y_train_pred)\n\n# Print the results for training data\nprint(f\"Training Mean Squared Error (MSE): {mse_train}\")\nprint(f\"Training R-squared (R2): {r2_train}\")\n\ntree_rules = export_text(regressor, feature_names=list(X.columns))\nprint(f\"\\nDecision Tree:\\n{tree_rules}\")\n\n# Plot the decision tree\nplt.figure(figsize=(12, 8))\nplot_tree(regressor, feature_names=list(X.columns), filled=True, rounded=True, fontsize=10)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:36.302948Z","iopub.execute_input":"2024-03-19T15:37:36.303261Z","iopub.status.idle":"2024-03-19T15:37:38.786339Z","shell.execute_reply.started":"2024-03-19T15:37:36.303233Z","shell.execute_reply":"2024-03-19T15:37:38.785153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cost complexity pruning regularization for decision tree find best alpha value\npath = regressor.cost_complexity_pruning_path(X_train, y_train)\nalphas, impurities = path.ccp_alphas, path.impurities\nmse_values = []\n\n#Loop through alpha values to find the best one that results in lowest mse in left-out sample for cv\nfor alpha in alphas:\n    # Create and fit the Decision Tree with the current alpha\n    tree = DecisionTreeRegressor(ccp_alpha=alpha, random_state=0)\n    \n    # Perform 5-fold cross-validation\n    scores = cross_val_score(tree, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n    \n    # Calculate and store the Mean Squared Error (MSE) for the current alpha\n    mse = -scores.mean()\n    mse_values.append(mse)\n\n# Create a DataFrame to store alpha and corresponding mean squared errors\neva_df = pd.DataFrame({'alpha': alphas, 'mse': mse_values})\neva_df = eva_df.sort_values(['mse'], ascending=True)\neva_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:38.787940Z","iopub.execute_input":"2024-03-19T15:37:38.788336Z","iopub.status.idle":"2024-03-19T15:37:39.712909Z","shell.execute_reply.started":"2024-03-19T15:37:38.788302Z","shell.execute_reply":"2024-03-19T15:37:39.711911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print out all possible alpha values that were considered in the array\n\npath = tree.cost_complexity_pruning_path(X_train, y_train)\nalphas = path.ccp_alphas\n\nprint(\"Array of alpha values:\")\nprint(alphas)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:39.714360Z","iopub.execute_input":"2024-03-19T15:37:39.715087Z","iopub.status.idle":"2024-03-19T15:37:39.725952Z","shell.execute_reply.started":"2024-03-19T15:37:39.715045Z","shell.execute_reply":"2024-03-19T15:37:39.724857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Make tree with best alpha\n\nprunedtree = DecisionTreeRegressor(ccp_alpha=0.002154)\n# Fit the model on the training data\nprunedtree.fit(X_train, y_train)\n\n# Make predictions on the training set\ny_train_pred2 = prunedtree.predict(X_train)\n\n# Calculate MSE and R-squared for training data\nmse_train2 = mean_squared_error(y_train, y_train_pred2)\nr2_train2 = r2_score(y_train, y_train_pred2)\n\n# Print the results for training data\nprint(f\"Training Mean Squared Error (MSE): {mse_train2}\")\nprint(f\"Training R-squared (R2): {r2_train2}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:39.727703Z","iopub.execute_input":"2024-03-19T15:37:39.728274Z","iopub.status.idle":"2024-03-19T15:37:39.744549Z","shell.execute_reply.started":"2024-03-19T15:37:39.728227Z","shell.execute_reply":"2024-03-19T15:37:39.743111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Display tree\n\ntree_rules1 = export_text(prunedtree, feature_names=list(X.columns))\nprint(f\"\\nDecision Tree:\\n{tree_rules1}\")\n\n#Plot the decision tree\nplt.figure(figsize=(9,9))\nplot_tree(prunedtree, feature_names=list(X.columns), filled=True, rounded=True, fontsize=10)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:39.746128Z","iopub.execute_input":"2024-03-19T15:37:39.746530Z","iopub.status.idle":"2024-03-19T15:37:40.132125Z","shell.execute_reply.started":"2024-03-19T15:37:39.746489Z","shell.execute_reply":"2024-03-19T15:37:40.130989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Try a tree with poisson improvement parameter\n\nmodel3 = DecisionTreeRegressor(criterion = 'poisson')\n# Fit the model on the training data\nmodel3.fit(X_train, y_train)\n\n# Make predictions on the training set\ny_train_pred3 = model3.predict(X_train)\n\n# Calculate MSE and R-squared for training data\nmse_train3 = mean_squared_error(y_train, y_train_pred3)\nr2_train3 = r2_score(y_train, y_train_pred3)\n\n# Print the results for training data\nprint(f\"Training Mean Squared Error (MSE): {mse_train3}\")\nprint(f\"Training R-squared (R2): {r2_train3}\")\n\n\ntree_rules2 = export_text(model3, feature_names=list(X.columns))\nprint(f\"\\nDecision Tree:\\n{tree_rules2}\")\n\n#Plot the decision tree\nplt.figure(figsize=(20,20))\nplot_tree(model3, feature_names=list(X.columns), filled=True, rounded=True, fontsize=10)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:40.133689Z","iopub.execute_input":"2024-03-19T15:37:40.133987Z","iopub.status.idle":"2024-03-19T15:37:45.526945Z","shell.execute_reply.started":"2024-03-19T15:37:40.133960Z","shell.execute_reply":"2024-03-19T15:37:45.525940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Gridsearch tree\nfrom sklearn.model_selection import GridSearchCV\n\n# Define the hyperparameter grid\nparam_grid = {\n    'max_depth': [None, 1,2,3,4],           \n    'min_samples_split': [2,3,4,5,6,7,8,9,10],       \n    'min_samples_leaf': [5,10,15,20,25,30,40,50,60,70,80,90,100,110,120,130,140,150],\n    'max_leaf_nodes' : [2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n}\n\n\n# Create a Decision Tree regressor\ngriddt = DecisionTreeRegressor(random_state=0)\n\n# Instantiate the GridSearchCV object\ngrid_search = GridSearchCV(griddt, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n\n# Fit the model to the data\ngrid_search.fit(X_train, y_train)\n\n# Get the best hyperparameters\nbest_params = grid_search.best_params_\n\n# Print the best hyperparameters\nprint(\"Best Hyperparameters:\", best_params)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:37:45.528432Z","iopub.execute_input":"2024-03-19T15:37:45.528758Z","iopub.status.idle":"2024-03-19T15:40:02.317200Z","shell.execute_reply.started":"2024-03-19T15:37:45.528731Z","shell.execute_reply":"2024-03-19T15:40:02.316197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Make new tree with best parameters from grid search\n\ndtsearch = DecisionTreeRegressor(max_leaf_nodes=8, min_samples_leaf = 5, min_samples_split=2)\n# Fit the model on the training data\ndtsearch.fit(X_train, y_train)\n\n# Make predictions on the training set\ny_train_pred4 = dtsearch.predict(X_train)\n\n# Calculate MSE and R-squared for training data\nmse_train4 = mean_squared_error(y_train, y_train_pred4)\nr2_train4 = r2_score(y_train, y_train_pred4)\n\n# Print the results for training data\nprint(f\"Training Mean Squared Error (MSE): {mse_train4}\")\nprint(f\"Training R-squared (R2): {r2_train4}\")\n\n\ntree_rules4 = export_text(dtsearch, feature_names=list(X.columns))\nprint(f\"\\nDecision Tree:\\n{tree_rules4}\")\n\n#Plot the decision tree\nplt.figure(figsize=(10,9))\nplot_tree(dtsearch, feature_names=list(X.columns), filled=True, rounded=True, fontsize=10)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:02.318717Z","iopub.execute_input":"2024-03-19T15:40:02.319587Z","iopub.status.idle":"2024-03-19T15:40:02.943884Z","shell.execute_reply.started":"2024-03-19T15:40:02.319542Z","shell.execute_reply":"2024-03-19T15:40:02.942729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Linear Regressions**","metadata":{}},{"cell_type":"code","source":"#Run ordinary least squares with everything to see what our ceiling is\n\nresults = {}\n\npoly_features = PolynomialFeatures(degree=1)\nX_train_poly = poly_features.fit_transform(X_train)\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train_poly, y_train)\n\n# Make predictions on the training set\ny_train_pred = model.predict(X_train_poly)\n\n# Calculate MSE on the training set\nmse_train = mean_squared_error(y_train, y_train_pred)\nresults[f'Degree_{1}'] = {'Model': model, 'MSE_train': mse_train}\n    \n# Calculate R-squared on the training set\nr2_train = r2_score(y_train, y_train_pred)\n\n# Extract coefficients to form the equation\ncoefficients = model.coef_\nintercept = model.intercept_\n\nequation = f\"y = {intercept:.4f} \"\nfor i, coef in enumerate(coefficients[1:], start=1):\n    equation += f\"+ {coef:.4f} * x{i} \"\n\nresults[f'Degree_{1}'] = {'Model': model, 'MSE_train': mse_train, 'R2_train': r2_train, 'Equation': equation}\n\n# Print the training set MSE, R-squared, and equation for each degree\n\nprint('Ordinary Least Squares:')\nprint('Training Set MSE:', mse_train)\nprint('Training Set R-squared:', r2_train)\nprint('Equation:', equation)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:02.945721Z","iopub.execute_input":"2024-03-19T15:40:02.946154Z","iopub.status.idle":"2024-03-19T15:40:02.965808Z","shell.execute_reply.started":"2024-03-19T15:40:02.946112Z","shell.execute_reply":"2024-03-19T15:40:02.964723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Run lasso to highlight important features\n\nlassocv = LassoCV(alphas=None, cv=5, max_iter=100000)\nlassocv.fit(X_train, y_train)\n# Set Lasso model with the best alpha from LassoCV\nlasso = Lasso(alpha=lassocv.alpha_)\n\n# Print the best alpha\nprint(\"Alpha =\", lassocv.alpha_)\n\n# Fit Lasso model\nlasso.fit(X_train, y_train)\n\n# Print MSE and coefficients\nprint(\"MSE =\", mean_squared_error(y_train, lasso.predict(X_train)))\nprint(\"Best model coefficients:\")\nprint(pd.Series(lasso.coef_, index=X.columns))","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:02.967080Z","iopub.execute_input":"2024-03-19T15:40:02.967397Z","iopub.status.idle":"2024-03-19T15:40:03.041581Z","shell.execute_reply.started":"2024-03-19T15:40:02.967369Z","shell.execute_reply":"2024-03-19T15:40:03.040534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot how coefficients change with alpha\nalphas = lassocv.alphas_\ncoefs = []\n\n# Fit Lasso models for each alpha and store coefficients\nfor alpha in alphas:\n    lasso.alpha = alpha\n    lasso.fit(X_train, y_train)\n    coefs.append(lasso.coef_)\n\n# Convert the list of coefficients to a NumPy array\ncoefs = np.array(coefs)\n\nplt.figure(figsize=(12, 8))\nplt.plot(alphas, coefs, marker='o')\nplt.xscale('log')\nplt.xlabel('Alpha')\nplt.ylabel('Coefficient Values')\nplt.title('Lasso Coefficients as Alpha Increases')\nplt.legend(X.columns)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:03.043079Z","iopub.execute_input":"2024-03-19T15:40:03.043378Z","iopub.status.idle":"2024-03-19T15:40:04.246251Z","shell.execute_reply.started":"2024-03-19T15:40:03.043350Z","shell.execute_reply":"2024-03-19T15:40:04.245140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Difficult to interpret graph\n#Run again without the country dummy variables and A-E\nselected_IVs = ['sq_cabinet', 'sq_pm', 'election_year', 'miw_new', 'caretaker',\n       'prime_minister', 'latent_ideology', 'party_count',\n       'post_election', 'enpp', 'mingov', 'bicameral', 'largest_parl',\n       'lag_largest_parl', 'lag_largest_cab', 'seats_total', 'W',\n       'latent_pivotality', 'latent_seats']\nXselected = X_train[selected_IVs]\n\nlassocv2 = LassoCV(alphas=None, cv=5, max_iter=100000)\nlassocv2.fit(Xselected, y_train)\n# Set Lasso model with the best alpha from LassoCV\nlasso2 = Lasso(alpha=lassocv2.alpha_)\n\n# Print the best alpha\nprint(\"Alpha =\", lassocv2.alpha_)\n\n# Fit Lasso model on XQB, yQB\nlasso2.fit(Xselected, y_train)\n\n# Print MSE and coefficients\nprint(\"MSE =\", mean_squared_error(y_train, lasso2.predict(Xselected)))\nprint(\"Best model coefficients:\")\nprint(pd.Series(lasso2.coef_, index=Xselected.columns))\n\nbest_coefficients = lasso2.coef_\nfeature_names = Xselected.columns\n\n# Create the equation\nequation = \"y = \"\nfor i, coef in enumerate(best_coefficients):\n    if coef != 0:\n        if i == 0:\n            equation += f\"{coef:.4f} * {feature_names[i]}\"\n        else:\n            equation += f\" + {coef:.4f} * {feature_names[i]}\"\n\nprint(\"Lasso Regression Equation:\")\nprint(equation)\n\n# Make predictions on the training set\ny_train_pred_lasso = lasso2.predict(Xselected)\n\n# Calculate MSE and R-squared for training data\nmse_train_lasso = mean_squared_error(y_train, y_train_pred_lasso)\nr2_train_lasso = r2_score(y_train, y_train_pred_lasso)\n\n# Print results\nprint(f\"Training Mean Squared Error (MSE) for Lasso Regression: {mse_train_lasso}\")\nprint(f\"Training R-squared (R2) for Lasso Regression: {r2_train_lasso}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:04.249192Z","iopub.execute_input":"2024-03-19T15:40:04.249871Z","iopub.status.idle":"2024-03-19T15:40:04.328034Z","shell.execute_reply.started":"2024-03-19T15:40:04.249831Z","shell.execute_reply":"2024-03-19T15:40:04.327086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot how coefficients change with alpha\nalphas2 = lassocv2.alphas_\ncoefs2 = []\n\n# Fit Lasso models for each alpha and store coefficients\nfor alpha in alphas2:\n    lasso2.alpha = alpha\n    lasso2.fit(Xselected, y_train)\n    coefs2.append(lasso2.coef_)\n\n# Convert the list of coefficients to a NumPy array\ncoefs2 = np.array(coefs2)\n\nplt.figure(figsize=(10,10))\nplt.plot(alphas2, coefs2, marker='o')\nplt.xscale('log')\nplt.xlabel('Alpha')\nplt.ylabel('Coefficient Values')\nplt.title('Lasso Coefficients as Alpha Increases')\nplt.legend(Xselected.columns)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:04.329205Z","iopub.execute_input":"2024-03-19T15:40:04.329532Z","iopub.status.idle":"2024-03-19T15:40:05.399870Z","shell.execute_reply.started":"2024-03-19T15:40:04.329505Z","shell.execute_reply":"2024-03-19T15:40:05.398945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Run linear regression and poly with coefficients that remained at best alpha value\nfrom sklearn.model_selection import cross_val_score, KFold\n\nlassoIVs = ['prime_minister', 'latent_pivotality', 'latent_seats', 'mingov', 'enpp', 'sq_cabinet', 'sq_pm', \n           'miw_new', 'party_count', 'seats_total', 'W']\nXlasso = X_train[lassoIVs]\nXlasso_test = X_test[lassoIVs]\n\n# Define degrees for polynomial features\ndegrees = [1, 2, 3]\n\nfor degree in degrees:\n    # Create a pipeline with PolynomialFeatures and Lasso regression\n    model_las = make_pipeline(PolynomialFeatures(degree), LassoCV(cv=KFold(n_splits=5, shuffle=True, random_state=42)))\n    \n    # Fit the model\n    model_las.fit(Xlasso, y_train)\n\n    # Print training MSE and R-squared\n    y_pred_train_las = model_las.predict(Xlasso)\n    mse_train_las = mean_squared_error(y_train, y_pred_train_las)\n    r2_train_las = r2_score(y_train, y_pred_train_las)\n\n    print(f\"\\nDegree {degree} Polynomial Features:\")\n    print(f\"Training Mean Squared Error (MSE): {mse_train_las}\")\n    print(f\"Training R-squared (R2): {r2_train_las}\")\n    \n    # Predict on the test data\n    #I added these calculations on test results only after I ran all my other models. I couldn't figure out how to calculate test mse\n    # and test r-squared outside of this for loop\n    y_pred_test_las = model_las.predict(Xlasso_test)\n    \n    # Calculate MSE and R-squared for the test data\n    mse_test_las = mean_squared_error(y_test, y_pred_test_las)\n    r2_test_las = r2_score(y_test, y_pred_test_las)\n\n    print(f\"Degree {degree} Polynomial Features (Testing):\")\n    print(f\"Test Mean Squared Error (MSE): {mse_test_las}\")\n    print(f\"Test R-squared (R2): {r2_test_las}\")\n    \n   \n    \n    # Extract coefficients and create the equation\n    if degree == 1:\n        coefs_las = model_las.named_steps['lassocv'].coef_\n        equation = f\"y = {coefs_las[0]:.4f}\"\n        for i, coef_las in enumerate(coefs_las[1:], start=1):\n            equation += f\" + {coef_las:.4f} * X{i}\"\n    else:\n        coefs_las = model_las.named_steps['lassocv'].coef_\n        equation = f\"y = {coefs_las[0]:.4f}\"\n        for i, coef_las in enumerate(coefs_las[1:], start=1):\n            equation += f\" + {coef_las:.4f} * X{i}^{degree}\"\n\n    print(f\"Equation: {equation}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:05.401646Z","iopub.execute_input":"2024-03-19T15:40:05.402081Z","iopub.status.idle":"2024-03-19T15:40:08.674780Z","shell.execute_reply.started":"2024-03-19T15:40:05.402033Z","shell.execute_reply":"2024-03-19T15:40:08.673681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#See which of the pivotality variables matters the most\n#Import new df with just the DV and pivotality vars\npv = pd.read_csv('../input/pivotalityvars/PivotalityVars.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:08.676719Z","iopub.execute_input":"2024-03-19T15:40:08.677568Z","iopub.status.idle":"2024-03-19T15:40:08.691122Z","shell.execute_reply.started":"2024-03-19T15:40:08.677518Z","shell.execute_reply":"2024-03-19T15:40:08.689782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xpv = pv.drop('cabinet_proportion', axis=1)  # Dataframe of IVs\nypv = pv['cabinet_proportion']  #Dataframe of DV","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:08.693033Z","iopub.execute_input":"2024-03-19T15:40:08.693434Z","iopub.status.idle":"2024-03-19T15:40:08.704522Z","shell.execute_reply.started":"2024-03-19T15:40:08.693395Z","shell.execute_reply":"2024-03-19T15:40:08.703083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform a train-test split\nXpv_train, Xpv_test, ypv_train, ypv_test = train_test_split(Xpv, ypv, test_size=0.4, random_state=51)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:08.707163Z","iopub.execute_input":"2024-03-19T15:40:08.708431Z","iopub.status.idle":"2024-03-19T15:40:08.720871Z","shell.execute_reply.started":"2024-03-19T15:40:08.708385Z","shell.execute_reply":"2024-03-19T15:40:08.719248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Run lasso to highlight important features\n\nlassocvpv = LassoCV(alphas=None, cv=5, max_iter=100000)\nlassocvpv.fit(Xpv_train, ypv_train)\n# Set Lasso model with the best alpha from LassoCV\nlassopv = Lasso(alpha=lassocv.alpha_)\n\n# Print the best alpha\nprint(\"Alpha =\", lassocvpv.alpha_)\n\n# Fit Lasso model\nlassopv.fit(Xpv_train, ypv_train)\n\n# Print MSE and coefficients\nprint(\"MSE =\", mean_squared_error(ypv_train, lassopv.predict(Xpv_train)))\nprint(\"Best model coefficients:\")\nprint(pd.Series(lassopv.coef_, index=Xpv.columns))","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:08.722991Z","iopub.execute_input":"2024-03-19T15:40:08.724344Z","iopub.status.idle":"2024-03-19T15:40:08.840110Z","shell.execute_reply.started":"2024-03-19T15:40:08.724300Z","shell.execute_reply":"2024-03-19T15:40:08.838925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot how coefficients change with alpha\nalphaspv = lassocvpv.alphas_\ncoefspv = []\n\n# Fit Lasso models for each alpha and store coefficients\nfor alpha in alphaspv:\n    lassopv.alpha = alpha\n    lassopv.fit(Xpv_train, ypv_train)\n    coefspv.append(lassopv.coef_)\n\n# Convert the list of coefficients to a NumPy array\ncoefspv = np.array(coefspv)\n\nplt.figure(figsize=(12, 8))\nplt.plot(alphaspv, coefspv, marker='o')\nplt.xscale('log')\nplt.xlabel('Alpha')\nplt.ylabel('Coefficient Values')\nplt.title('Lasso Coefficients as Alpha Increases')\nplt.legend(Xpv.columns)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:08.841527Z","iopub.execute_input":"2024-03-19T15:40:08.841931Z","iopub.status.idle":"2024-03-19T15:40:09.632628Z","shell.execute_reply.started":"2024-03-19T15:40:08.841893Z","shell.execute_reply":"2024-03-19T15:40:09.631780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test OOS for all models**","metadata":{}},{"cell_type":"code","source":"#Everything DT\n# Make predictions on the training set\ny_test_pred1 = regressor.predict(X_test)\n\n# Calculate MSE and R-squared for training data\nmse_test1 = mean_squared_error(y_test, y_test_pred1)\nr2_test1 = r2_score(y_test, y_test_pred1)\n\n# Print the results for training data\nprint(f\"Test Mean Squared Error (MSE): {mse_test1}\")\nprint(f\"Test R-squared (R2): {r2_test1}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:09.633894Z","iopub.execute_input":"2024-03-19T15:40:09.634202Z","iopub.status.idle":"2024-03-19T15:40:09.644280Z","shell.execute_reply.started":"2024-03-19T15:40:09.634176Z","shell.execute_reply":"2024-03-19T15:40:09.643507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CCP DT\ny_test_pred2 = prunedtree.predict(X_test)\n\n# Calculate MSE and R-squared for training data\nmse_test2 = mean_squared_error(y_test, y_test_pred2)\nr2_test2 = r2_score(y_test, y_test_pred2)\n\n# Print the results for training data\nprint(f\"Test Mean Squared Error (MSE): {mse_test2}\")\nprint(f\"Test R-squared (R2): {r2_test2}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:09.645483Z","iopub.execute_input":"2024-03-19T15:40:09.645817Z","iopub.status.idle":"2024-03-19T15:40:09.660562Z","shell.execute_reply.started":"2024-03-19T15:40:09.645786Z","shell.execute_reply":"2024-03-19T15:40:09.659375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Improvement parameter DT\ny_test_pred3 = model3.predict(X_test)\n\n# Calculate MSE and R-squared for training data\nmse_test3 = mean_squared_error(y_test, y_test_pred3)\nr2_test3 = r2_score(y_test, y_test_pred3)\n\n# Print the results for training data\nprint(f\"Test Mean Squared Error (MSE): {mse_test3}\")\nprint(f\"Test R-squared (R2): {r2_test3}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:09.661907Z","iopub.execute_input":"2024-03-19T15:40:09.662269Z","iopub.status.idle":"2024-03-19T15:40:09.674495Z","shell.execute_reply.started":"2024-03-19T15:40:09.662235Z","shell.execute_reply":"2024-03-19T15:40:09.673588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Grid search DT\ny_test_pred4 = grid_search.predict(X_test)\n\n# Calculate MSE and R-squared for training data\nmse_test4 = mean_squared_error(y_test, y_test_pred4)\nr2_test4 = r2_score(y_test, y_test_pred4)\n\n# Print the results for training data\nprint(f\"Test Mean Squared Error (MSE): {mse_test4}\")\nprint(f\"Test R-squared (R2): {r2_test4}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:09.675727Z","iopub.execute_input":"2024-03-19T15:40:09.676045Z","iopub.status.idle":"2024-03-19T15:40:09.689479Z","shell.execute_reply.started":"2024-03-19T15:40:09.676016Z","shell.execute_reply":"2024-03-19T15:40:09.688399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ordinary least squares\nX_test_poly1 = poly_features.fit_transform(X_test)\n\ny_test_pred5 = model.predict(X_test_poly1)\n\n# Calculate MSE and R-squared for training data\nmse_test5 = mean_squared_error(y_test, y_test_pred5)\nr2_test5 = r2_score(y_test, y_test_pred5)\n\n# Print the results for training data\nprint(f\"Test Mean Squared Error (MSE): {mse_test5}\")\nprint(f\"Test R-squared (R2): {r2_test5}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:09.690717Z","iopub.execute_input":"2024-03-19T15:40:09.691047Z","iopub.status.idle":"2024-03-19T15:40:09.703741Z","shell.execute_reply.started":"2024-03-19T15:40:09.691011Z","shell.execute_reply":"2024-03-19T15:40:09.702601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lasso\n\nX_test_selected = X_test[selected_IVs]\n\ny_test_pred6 = lasso2.predict(X_test_selected)\n\n# Calculate MSE and R-squared for training data\nmse_test6 = mean_squared_error(y_test, y_test_pred6)\nr2_test6 = r2_score(y_test, y_test_pred6)\n\n# Print the results for training data\nprint(f\"Test Mean Squared Error (MSE): {mse_test6}\")\nprint(f\"Test R-squared (R2): {r2_test6}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:09.705542Z","iopub.execute_input":"2024-03-19T15:40:09.705998Z","iopub.status.idle":"2024-03-19T15:40:09.720453Z","shell.execute_reply.started":"2024-03-19T15:40:09.705957Z","shell.execute_reply":"2024-03-19T15:40:09.719476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Degrees 1-3 from lasso (just copied from above because had to put it in the for loop)\nprint('Degree 1 test mse: ', 0.02616812530861612)\nprint('Degree 1 test r squared: ', 0.47800873546861355)\nprint('Degree 2 test mse: ', 0.019400048245876867)\nprint('Degree 2 test r squared: ', 0.613015621241279)\nprint('Degree 3 test mse: ', 0.02208990850953732)\nprint('Degree 3 test r squared: ', 0.5593593679223399)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:40:09.721823Z","iopub.execute_input":"2024-03-19T15:40:09.722695Z","iopub.status.idle":"2024-03-19T15:40:09.732383Z","shell.execute_reply.started":"2024-03-19T15:40:09.722659Z","shell.execute_reply":"2024-03-19T15:40:09.731628Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
